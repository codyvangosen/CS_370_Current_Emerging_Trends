# CS_370_Current_Emerging_Trends
This is a repository of my project files and final submission for my final portfolio for the CS-370 Class at SNHU.


In this project, I developed an intelligent agent to autonomously navigate a maze and reach the designated goal using deep Q-learning reinforcement learning principles. The goal was to demonstrate how artificial intelligence (AI) can systematically solve complex problems.

Code Overview
Code Provided:
Starter maze environment setup.
Framework for reinforcement learning interaction.
Code Created:
Implementation of the Deep Q-Learning algorithm using neural networks.
Custom logic for exploration-exploitation balancing (epsilon-greedy strategy).
Reward and penalty system to optimize the agent's navigation.
Neural network architecture with input, hidden layers, and output layers using ReLU activation.
Experience replay mechanism for improved learning efficiency.
Performance evaluation to validate the intelligent agent's success.
Connection to the Field of Computer Science
1. What Do Computer Scientists Do and Why Does It Matter?
Computer scientists analyze, design, and implement systems to solve problems across a range of domains, including healthcare, automation, and artificial intelligence. This project highlights the role of computer scientists in developing intelligent systems that can outperform human intuition in certain tasks, such as maze navigation. By leveraging deep Q-learning, the agent learns optimal solutions systematically, demonstrating the transformative impact of AI and machine learning.

2. Approaching Problems as a Computer Scientist
As a computer scientist, problem-solving involves breaking a challenge into smaller, manageable components and applying systematic methods to address them. For this project:

Defining the Problem: Developing an intelligent agent to solve a maze efficiently.
Exploring Algorithms: Choosing reinforcement learning (Deep Q-Learning) for adaptability and optimization.
Iterative Development: Testing and refining the agent's performance through feedback and experience replay.
Balancing Exploration and Exploitation: Using the epsilon-greedy strategy to ensure the agent learns effectively.
This structured approach is critical to achieving reliable and scalable solutions.

3. Ethical Responsibilities to the End User and Organization
As computer scientists, we hold ethical responsibilities to ensure that the technologies we develop are fair, transparent, and beneficial:

End Users: The solutions must be reliable, optimized, and free of biases that could negatively impact users. In reinforcement learning, biases in training data or algorithms could result in inefficient or unintended behavior.
Organizations: We are responsible for producing systems that are resource-efficient, maintainable, and secure. In this project, ensuring the agent balances learning efficiency and computational costs aligns with these responsibilities.
By adhering to these ethical principles, computer scientists contribute to trustworthy and impactful technologies.

Key Learnings
This project strengthened my understanding of reinforcement learning, deep neural networks, and problem-solving in artificial intelligence. I gained hands-on experience implementing AI techniques, balancing system constraints, and validating the solutionâ€™s performance. These skills are foundational to advancing intelligent systems and solving real-world problems.
